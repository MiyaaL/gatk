{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://fc-secure-089622a2-ae22-4dc8-ad01-634bd7634d5f/keys/aou_wgs_vumc_prod.json...\n",
      "/ [1 files][  2.3 KiB/  2.3 KiB]                                                \n",
      "Operation completed over 1 objects/2.3 KiB.                                      \n",
      "Copying gs://fc-secure-062111d2-d6d9-4613-85c0-1809d891faa6/notebooks/filter_set_samples_create_metrics.functions.sql...\n",
      "/ [1 files][  1.1 KiB/  1.1 KiB]                                                \n",
      "Operation completed over 1 objects/1.1 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp \"gs://fc-secure-089622a2-ae22-4dc8-ad01-634bd7634d5f/keys/aou_wgs_vumc_prod.json\" .\n",
    "!gsutil cp \"gs://fc-secure-062111d2-d6d9-4613-85c0-1809d891faa6/notebooks/filter_set_samples_create_metrics.functions.sql\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! # Notes --- \n",
    "! # when run on the Charlie callset, the original version of this query timed out, \n",
    "! # so it was updated to be 3 different queries\n",
    "! # The first two populate the table with duplicates by querying the prepare VET_DATA table twice (or however many times you need to get all the data)\n",
    "! # The third query groups on sample id (and filter--not sure why since it should be the same) to remove duplicates and sum everything up\n",
    "! # \n",
    "! # The best version of this would lkely be an intial query (or set of queries) that creates a temp table for the innter select statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery.job import QueryJobConfig\n",
    "from google.oauth2 import service_account\n",
    "from pathlib import Path\n",
    "\n",
    "FQ_PREFIX = \"aou-genomics-curation-prod.aou_wgs.charlie\"\n",
    "NAME_OF_FILTER_SET = \"charlie\"\n",
    "\n",
    "sa_key_path = \"aou_wgs_vumc_prod.json\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    sa_key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "job_config = QueryJobConfig(priority=\"INTERACTIVE\",\n",
    "                            use_query_cache=True)\n",
    "\n",
    "query_project = \"aou-genomics-curation-prod\"\n",
    "client = bigquery.Client(credentials=credentials,\n",
    "                         project=query_project,\n",
    "                         default_query_job_config=job_config)\n",
    "\n",
    "f = open(\"filter_set_samples_create_metrics.functions.sql\", \"r\")\n",
    "sql = \"\\n\".join(f.readlines())\n",
    "\n",
    "sql += f\"\"\"CREATE OR REPLACE TABLE `{FQ_PREFIX}_sample_metrics` AS\n",
    "SELECT \"{NAME_OF_FILTER_SET}\" filter_set_name,\n",
    "       sample_id,\n",
    "       count(1) variant_entries,\n",
    "       SUM(CASE WHEN type = \"del\" THEN 1 ELSE 0 END) del_count,\n",
    "       SUM(CASE WHEN type = \"ins\" THEN 1 ELSE 0 END) ins_count,\n",
    "       SUM(CASE WHEN type = \"snp\" THEN 1 ELSE 0 END) snp_count,\n",
    "       SUM(CASE WHEN type = \"snp\" AND titv = \"ti\" THEN 1 ELSE 0 END) ti_count, # TODO: minimize alleles\n",
    "       SUM(CASE WHEN type = \"snp\" AND titv = \"tv\" THEN 1 ELSE 0 END) tv_count, # TODO: minimize alleles\n",
    "       SUM(CASE WHEN type = \"snp\" AND gt_type = \"het\" THEN 1 ELSE 0 END) snp_het_count,\n",
    "       SUM(CASE WHEN type = \"snp\" AND gt_type = \"homvar\" THEN 1 ELSE 0 END) snp_homvar_count,\n",
    "       SUM(CASE WHEN type IN (\"ins\",\"del\") AND gt_type = \"het\" THEN 1 ELSE 0 END) indel_het_count,\n",
    "       SUM(CASE WHEN type IN (\"ins\",\"del\") AND gt_type = \"homvar\" THEN 1 ELSE 0 END) indel_homvar_count,\n",
    "       COUNTIF(not in_gnomad) singleton,\n",
    "       null AS pass_qc\n",
    "    FROM (\n",
    "        SELECT sample_id,\n",
    "               type(ref, alt, call_GT) as type,\n",
    "               CASE WHEN INSTR(call_GT, \"0\") > 0 THEN \"het\" ELSE \"homvar\" END as gt_type,\n",
    "               titv(ref, alt) as titv,\n",
    "               CASE WHEN gnomad.location IS NULL THEN false ELSE true END in_gnomad\n",
    "        FROM `{FQ_PREFIX}__VET_DATA` v\n",
    "        LEFT JOIN `spec-ops-aou.gvs_public_reference_data.gnomad_v3_sites` gnomad ON (v.location = gnomad.location)\n",
    "        WHERE call_GT != \"./.\"\n",
    "        AND v.location < 10000000000000) GROUP BY 1,2\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "print(\"STARTING\")\n",
    "query = client.query(sql, job_config=job_config)\n",
    "result = query.result()\n",
    "print(f\"COMPLETED {time.time() - start}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery.job import QueryJobConfig\n",
    "from google.oauth2 import service_account\n",
    "from pathlib import Path\n",
    "\n",
    "FQ_PREFIX = \"aou-genomics-curation-prod.aou_wgs.charlie\"\n",
    "NAME_OF_FILTER_SET = \"charlie\"\n",
    "\n",
    "sa_key_path = \"aou_wgs_vumc_prod.json\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    sa_key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "job_config = QueryJobConfig(priority=\"INTERACTIVE\",\n",
    "                            use_query_cache=True)\n",
    "\n",
    "query_project = \"aou-genomics-curation-prod\"\n",
    "client = bigquery.Client(credentials=credentials,\n",
    "                         project=query_project,\n",
    "                         default_query_job_config=job_config)\n",
    "\n",
    "f = open(\"filter_set_samples_create_metrics.functions.sql\", \"r\")\n",
    "sql = \"\\n\".join(f.readlines())\n",
    "\n",
    "sql += f\"\"\"\n",
    "\n",
    "INSERT `{FQ_PREFIX}_sample_metrics` (\n",
    "    filter_set_name,\n",
    "    sample_id,\n",
    "    variant_entries,\n",
    "    del_count, \n",
    "    ins_count,\n",
    "    snp_count,\n",
    "    ti_count,\n",
    "    tv_count,\n",
    "    snp_het_count,\n",
    "    snp_homvar_count,\n",
    "    indel_het_count,\n",
    "    indel_homvar_count,\n",
    "    singleton,\n",
    "    pass_qc\n",
    "    )\n",
    "SELECT \"{NAME_OF_FILTER_SET}\" filter_set_name,\n",
    "       sample_id,\n",
    "       count(1) variant_entries,\n",
    "       SUM(CASE WHEN type = \"del\" THEN 1 ELSE 0 END) del_count,\n",
    "       SUM(CASE WHEN type = \"ins\" THEN 1 ELSE 0 END) ins_count,\n",
    "       SUM(CASE WHEN type = \"snp\" THEN 1 ELSE 0 END) snp_count,\n",
    "       SUM(CASE WHEN type = \"snp\" AND titv = \"ti\" THEN 1 ELSE 0 END) ti_count, # TODO: minimize alleles\n",
    "       SUM(CASE WHEN type = \"snp\" AND titv = \"tv\" THEN 1 ELSE 0 END) tv_count, # TODO: minimize alleles\n",
    "       SUM(CASE WHEN type = \"snp\" AND gt_type = \"het\" THEN 1 ELSE 0 END) snp_het_count,\n",
    "       SUM(CASE WHEN type = \"snp\" AND gt_type = \"homvar\" THEN 1 ELSE 0 END) snp_homvar_count,\n",
    "       SUM(CASE WHEN type IN (\"ins\",\"del\") AND gt_type = \"het\" THEN 1 ELSE 0 END) indel_het_count,\n",
    "       SUM(CASE WHEN type IN (\"ins\",\"del\") AND gt_type = \"homvar\" THEN 1 ELSE 0 END) indel_homvar_count,\n",
    "       COUNTIF(not in_gnomad) singleton,\n",
    "       null AS pass_qc\n",
    "    FROM (\n",
    "        SELECT sample_id,\n",
    "               type(ref, alt, call_GT) as type,\n",
    "               CASE WHEN INSTR(call_GT, \"0\") > 0 THEN \"het\" ELSE \"homvar\" END as gt_type,\n",
    "               titv(ref, alt) as titv,\n",
    "               CASE WHEN gnomad.location IS NULL THEN false ELSE true END in_gnomad\n",
    "        FROM `{FQ_PREFIX}__VET_DATA` v\n",
    "        LEFT JOIN `spec-ops-aou.gvs_public_reference_data.gnomad_v3_sites` gnomad ON (v.location = gnomad.location)\n",
    "        WHERE call_GT != \"./.\"\n",
    "        AND v.location >= 10000000000000\n",
    "        AND v.location < 23000000000000) GROUP BY 1,2\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "print(\"STARTING\")\n",
    "query = client.query(sql, job_config=job_config)\n",
    "result = query.result()\n",
    "print(f\"COMPLETED {time.time() - start}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery.job import QueryJobConfig\n",
    "from google.oauth2 import service_account\n",
    "from pathlib import Path\n",
    "\n",
    "FQ_PREFIX = \"aou-genomics-curation-prod.aou_wgs.charlie\"\n",
    "NAME_OF_FILTER_SET = \"charlie\"\n",
    "\n",
    "sa_key_path = \"aou_wgs_vumc_prod.json\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    sa_key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "job_config = QueryJobConfig(priority=\"INTERACTIVE\",\n",
    "                            use_query_cache=True)\n",
    "\n",
    "query_project = \"aou-genomics-curation-prod\"\n",
    "client = bigquery.Client(credentials=credentials,\n",
    "                         project=query_project,\n",
    "                         default_query_job_config=job_config)\n",
    "\n",
    "f = open(\"filter_set_samples_create_metrics.functions.sql\", \"r\")\n",
    "sql = \"\\n\".join(f.readlines())\n",
    "\n",
    "sql += f\"\"\"CREATE OR REPLACE TABLE `{FQ_PREFIX}_sample_metrics_agg` AS\n",
    "SELECT \"{NAME_OF_FILTER_SET}\" filter_set_name,\n",
    "       sample_id,\n",
    "       SUM(variant_entries) variant_entries,\n",
    "       SUM(CASE WHEN type = \"del\" THEN 1 ELSE 0 END) del_count,\n",
    "       SUM(CASE WHEN type = \"ins\" THEN 1 ELSE 0 END) ins_count,\n",
    "       SUM(CASE WHEN type = \"snp\" THEN 1 ELSE 0 END) snp_count,\n",
    "       SUM(CASE WHEN type = \"snp\" AND titv = \"ti\" THEN 1 ELSE 0 END) ti_count, # TODO: minimize alleles\n",
    "       SUM(CASE WHEN type = \"snp\" AND titv = \"tv\" THEN 1 ELSE 0 END) tv_count, # TODO: minimize alleles\n",
    "       SUM(CASE WHEN type = \"snp\" AND gt_type = \"het\" THEN 1 ELSE 0 END) snp_het_count,\n",
    "       SUM(CASE WHEN type = \"snp\" AND gt_type = \"homvar\" THEN 1 ELSE 0 END) snp_homvar_count,\n",
    "       SUM(CASE WHEN type IN (\"ins\",\"del\") AND gt_type = \"het\" THEN 1 ELSE 0 END) indel_het_count,\n",
    "       SUM(CASE WHEN type IN (\"ins\",\"del\") AND gt_type = \"homvar\" THEN 1 ELSE 0 END) indel_homvar_count,\n",
    "       SUM(singleton) singleton,\n",
    "       null AS pass_qc\n",
    "    FROM `{FQ_PREFIX}_sample_metrics` GROUP BY 1,2\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "print(\"STARTING\")\n",
    "query = client.query(sql, job_config=job_config)\n",
    "result = query.result()\n",
    "print(f\"COMPLETED {time.time() - start}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n",
      "COMPLETED 9.259913206100464s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery.job import QueryJobConfig\n",
    "from google.oauth2 import service_account\n",
    "from pathlib import Path\n",
    "\n",
    "FQ_PREFIX = \"aou-genomics-curation-prod.aou_wgs.charlie\"\n",
    "NAME_OF_FILTER_SET = \"charlie\"\n",
    "DESTINATION = f\"{FQ_PREFIX}_samples_stats\"\n",
    "\n",
    "sa_key_path = \"aou_wgs_vumc_prod.json\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    sa_key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "job_config = QueryJobConfig(priority=\"INTERACTIVE\",\n",
    "                            use_query_cache=True,\n",
    "                            destination=f\"{DESTINATION}\")\n",
    "\n",
    "query_project = \"aou-genomics-curation-prod\"\n",
    "client = bigquery.Client(credentials=credentials,\n",
    "                         project=query_project,\n",
    "                         default_query_job_config=job_config)\n",
    "\n",
    "\n",
    "sql = f\"\"\"WITH fss AS (\n",
    "  SELECT *, \n",
    "         (ins_count / del_count) as ins_del_ratio, \n",
    "         (ti_count / tv_count) as ti_tv_ratio, \n",
    "         (snp_het_count / snp_homvar_count) snp_het_homvar_ratio, \n",
    "         (indel_het_count / indel_homvar_count) as indel_het_homvar_ratio\n",
    "  FROM `{FQ_PREFIX}_sample_metrics_agg`\n",
    "  WHERE filter_set_name = '{NAME_OF_FILTER_SET}'),\n",
    "medians AS ( \n",
    "    SELECT \n",
    "        `bqutil`.fn.median(ARRAY_AGG(del_count IGNORE NULLS)) as m_del_count,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ins_count IGNORE NULLS)) as m_ins_count,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(snp_count IGNORE NULLS)) as m_snp_count,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(singleton IGNORE NULLS)) as m_singleton,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ins_del_ratio IGNORE NULLS)) as m_ins_del_ratio,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ti_tv_ratio IGNORE NULLS)) as m_ti_tv_ratio,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(snp_het_homvar_ratio IGNORE NULLS)) as m_snp_het_homvar_ratio,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(indel_het_homvar_ratio IGNORE NULLS)) as m_indel_het_homvar_ratio        \n",
    "    FROM fss),\n",
    "mads AS (\n",
    "    SELECT \n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(del_count - m_del_count) IGNORE NULLS)) as mad_del_count,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(ins_count - m_ins_count) IGNORE NULLS)) as mad_ins_count,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(snp_count - m_snp_count) IGNORE NULLS)) as mad_snp_count,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(singleton - m_singleton) IGNORE NULLS)) as mad_singleton,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(ins_del_ratio - m_ins_del_ratio) IGNORE NULLS)) as mad_ins_del_ratio,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(ti_tv_ratio - m_ti_tv_ratio) IGNORE NULLS)) as mad_ti_tv_ratio,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(snp_het_homvar_ratio - m_snp_het_homvar_ratio) IGNORE NULLS)) as mad_snp_het_homvar_ratio,\n",
    "        `bqutil`.fn.median(ARRAY_AGG(ABS(indel_het_homvar_ratio - m_indel_het_homvar_ratio) IGNORE NULLS)) as mad_indel_het_homvar_ratio\n",
    "    FROM fss\n",
    "    CROSS JOIN medians \n",
    "    WHERE filter_set_name = '{NAME_OF_FILTER_SET}')\n",
    "\n",
    "SELECT \n",
    "    fss.sample_id,\n",
    "    si.sample_name,\n",
    "    del_count, m_del_count, mad_del_count,\n",
    "    CASE WHEN del_count BETWEEN m_del_count - 4*mad_del_count AND m_del_count + 4*mad_del_count THEN true ELSE false END pass_del_count,\n",
    "    \n",
    "    ins_count, m_ins_count, mad_ins_count,\n",
    "    CASE WHEN ins_count BETWEEN m_ins_count - 4*mad_ins_count AND m_ins_count + 4*mad_ins_count THEN true ELSE false END pass_ins_count,\n",
    "\n",
    "    snp_count, m_snp_count, mad_snp_count,\n",
    "    CASE WHEN snp_count BETWEEN m_snp_count - 4*mad_snp_count AND m_snp_count + 4*mad_snp_count THEN true ELSE false END pass_snp_count,\n",
    "\n",
    "    singleton, m_singleton, mad_singleton,\n",
    "    CASE WHEN singleton BETWEEN m_singleton - 8*mad_singleton AND m_singleton + 8*mad_singleton THEN true ELSE false END pass_singleton,\n",
    "    \n",
    "    ins_del_ratio, m_ins_del_ratio, mad_ins_del_ratio,\n",
    "    CASE WHEN ins_del_ratio BETWEEN m_ins_del_ratio - 4*mad_ins_del_ratio AND m_ins_del_ratio + 4*mad_ins_del_ratio THEN true ELSE false END pass_ins_del_ratio,\n",
    "\n",
    "    ti_tv_ratio, m_ti_tv_ratio, mad_ti_tv_ratio,\n",
    "    CASE WHEN ti_tv_ratio BETWEEN m_ti_tv_ratio - 4*mad_ti_tv_ratio AND m_ti_tv_ratio + 4*mad_ti_tv_ratio THEN true ELSE false END pass_ti_tv_ratio,\n",
    "\n",
    "    snp_het_homvar_ratio, m_snp_het_homvar_ratio, mad_snp_het_homvar_ratio,\n",
    "    CASE WHEN snp_het_homvar_ratio BETWEEN m_snp_het_homvar_ratio - 4*mad_snp_het_homvar_ratio AND m_snp_het_homvar_ratio + 4*mad_snp_het_homvar_ratio THEN true ELSE false END pass_snp_het_homvar_ratio,\n",
    "\n",
    "    indel_het_homvar_ratio, m_indel_het_homvar_ratio, mad_indel_het_homvar_ratio,\n",
    "    CASE WHEN indel_het_homvar_ratio BETWEEN m_indel_het_homvar_ratio - 4*mad_indel_het_homvar_ratio AND m_indel_het_homvar_ratio + 4*mad_indel_het_homvar_ratio THEN true ELSE false END pass_indel_het_homvar_ratio,    \n",
    "FROM fss\n",
    "JOIN `{FQ_PREFIX}__SAMPLES` si ON (fss.sample_id = si.sample_id)\n",
    "CROSS JOIN medians \n",
    "CROSS JOIN mads\n",
    "order by 1\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "print(\"STARTING\")\n",
    "query = client.query(sql, job_config=job_config)\n",
    "result = query.result()\n",
    "print(f\"COMPLETED {time.time() - start}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://fc-secure-089622a2-ae22-4dc8-ad01-634bd7634d5f/keys/aou_wgs_vumc_prod.json...\n",
      "/ [1 files][  2.3 KiB/  2.3 KiB]                                                \n",
      "Operation completed over 1 objects/2.3 KiB.                                      \n",
      "Activated service account credentials for: [awardee-drcbroad@all-of-us-rdr-prod.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp \"gs://fc-secure-089622a2-ae22-4dc8-ad01-634bd7634d5f/keys/aou_wgs_vumc_prod.json\" local.service_account.json\n",
    "! export GOOGLE_APPLICATION_CREDENTIALS=local.service_account.json\n",
    "!gcloud auth activate-service-account --key-file=local.service_account.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported aou-genomics-curation-prod:aou_wgs.charlie_samples_stats to gs://prod-drc-broad/aou-wgs-charlie/aou-wgs-charlie_stats.csv\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "sa_key_path = \"aou_wgs_vumc_prod.json\"\n",
    "project = \"aou-genomics-curation-prod\"\n",
    "bucket_name = \"prod-drc-broad\"\n",
    "dataset_id = \"aou_wgs\"\n",
    "table_id = \"charlie_samples_stats\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    sa_key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "job_config = QueryJobConfig(priority=\"INTERACTIVE\",\n",
    "                            use_query_cache=True)\n",
    "\n",
    "client = bigquery.Client(credentials=credentials,\n",
    "                         project=project,\n",
    "                         default_query_job_config=job_config)\n",
    "\n",
    "\n",
    "destination_uri = f\"gs://{bucket_name}/aou-wgs-charlie/aou-wgs-charlie_stats.csv\"\n",
    "dataset_ref = bigquery.DatasetReference(project, dataset_id)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "extract_job = client.extract_table(\n",
    "    table_ref,\n",
    "    destination_uri,\n",
    "    location=\"US\",\n",
    ")  # API request\n",
    "extract_job.result()  # Waits for job to complete.\n",
    "\n",
    "print(\n",
    "    \"Exported {}:{}.{} to {}\".format(project, dataset_id, table_id, destination_uri)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://prod-drc-broad/aou-wgs-charlie/aou-wgs-charlie_stats.csv\r\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls gs://prod-drc-broad/aou-wgs-charlie/aou-wgs-charlie_stats.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20039\r\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls gs://prod-drc-broad/aou-wgs-charlie/*-charlie.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
